[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Health Policy Data Science Lab Manual",
    "section": "",
    "text": "Health Policy Data Science Lab Manual\nThe Health Policy Data Science Lab at Stanford is a group of interdisciplinary researchers who develop and apply quantitative methods to solve problems in health policy, leveraging techniques from statistics, computer science, economics, epidemiology, and decision science.\nThis manual will evolve over time to incorporate contributions from Lab members and collaborators. We drew inspiration from the lab manuals of our colleagues, including Jade Benjamin-Chung and Russ Poldrack.\nFeel free to draw from this manual (and please cite it if you do)!\n  This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.",
    "crumbs": [
      "Health Policy Data Science Lab Manual"
    ]
  },
  {
    "objectID": "chapters/01-culture.html#mutual-respect-in-the-lab",
    "href": "chapters/01-culture.html#mutual-respect-in-the-lab",
    "title": "1  Lab Culture",
    "section": "1.1 Mutual Respect in the Lab",
    "text": "1.1 Mutual Respect in the Lab\nWe strive for a culture of mutual respect in all of our communications, meetings, and policies. Please demonstrate respect for all Lab members by, for example, practicing active listening, speaking only for yourself and not others, and not dominating conversations. Mutual respect for each other’s time includes being prepared (including drafting agendas), planning ahead, and starting/ending meetings at the scheduled time.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lab Culture</span>"
    ]
  },
  {
    "objectID": "chapters/01-culture.html#respect-for-the-people-represented-in-study-data",
    "href": "chapters/01-culture.html#respect-for-the-people-represented-in-study-data",
    "title": "1  Lab Culture",
    "section": "1.2 Respect for the People Represented in Study Data",
    "text": "1.2 Respect for the People Represented in Study Data\nA key value in the Lab is deep respect for the people and communities whose information is represented in the data we study. We engage seriously in learning about the policies, institutional structures, societal biases, and lived experiences that underlie these data sources.\nThis respect also involves careful attention to data privacy and protection, discussed in Section 4.5.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lab Culture</span>"
    ]
  },
  {
    "objectID": "chapters/01-culture.html#sec-working-hours",
    "href": "chapters/01-culture.html#sec-working-hours",
    "title": "1  Lab Culture",
    "section": "1.3 Working Hours",
    "text": "1.3 Working Hours\nLab members are encouraged to work efficiently and effectively on a schedule that works well for them. We do not support a culture of overwork!\nDr. Rose does not expect you to be working in the evenings or on weekends and asks that you respect Lab members’ evening and weekend time as well. This includes not expecting Dr. Rose to review your work product, submit letters, or otherwise be available for typical work tasks outside business hours.\nWe embrace time off, breaks from meetings, and vacations!",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lab Culture</span>"
    ]
  },
  {
    "objectID": "chapters/01-culture.html#trainee-support-access-and-accomodations",
    "href": "chapters/01-culture.html#trainee-support-access-and-accomodations",
    "title": "1  Lab Culture",
    "section": "1.4 Trainee Support, Access, and Accomodations",
    "text": "1.4 Trainee Support, Access, and Accomodations\nYour physical and mental health are incredibly important. Please familiarize yourself with the mental health and crisis assistance resources available for students at Stanford as well as mental health resources for postdoctoral scholars.\nStanford is committed to providing equal educational opportunities for disabled students. Disabled students are a valued and essential part of the Stanford community. If you experience disability, please register with the Office of Accessible Education (OAE). Professional staff at OAE will evaluate your needs, support appropriate and reasonable accommodations, and prepare an Academic Accommodation Letter for faculty. If you already have an Academic Accommodation Letter, Stanford invites you to share your letter with your advisor. Academic Accommodation Letters should be shared at the earliest possible opportunity so we may partner with you and OAE to identify any barriers to access and inclusion that might be encountered in your experience.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lab Culture</span>"
    ]
  },
  {
    "objectID": "chapters/02-policies.html#joining-the-lab",
    "href": "chapters/02-policies.html#joining-the-lab",
    "title": "2  General Policies",
    "section": "2.1 Joining the Lab",
    "text": "2.1 Joining the Lab\nDr. Rose keeps a page updated on her website regarding whether she is taking new students, hiring postdocs, or available for dissertation committees. At Stanford, we’ve had students from many different graduate programs join the lab, including health policy, biomedical data science, computer science, and chemical engineering programs.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>General Policies</span>"
    ]
  },
  {
    "objectID": "chapters/02-policies.html#recurring-meetings",
    "href": "chapters/02-policies.html#recurring-meetings",
    "title": "2  General Policies",
    "section": "2.2 Recurring Meetings",
    "text": "2.2 Recurring Meetings\nLab trainees meet individually with Dr. Rose regularly. This is typically weekly or every other week depending on the needs of the trainee and their projects. Meetings are either 25 minutes or 50 minutes to allow for breaks between meetings. Dr. Rose expects trainees to manage the meeting such that it ends on time.\nIn general, Dr. Rose expects progress to be made between each meeting. Progress can include struggling with the material. Dr. Rose cares that you are engaged and taking initiative to advance the project. We’ll discuss what you learned and where you are still confused. When we identify areas where you have gaps, Dr. Rose does expect you to invest in learning the required material and to follow through to fill those gaps. All trainees must be making satisfactory academic progress in line with the expectations of their graduate degree program.\nIf you do not need to meet a particular week (e.g., making steady progress and don’t have questions, busy preparing for an exam and did not work on research that week, etc), please email Dr. Rose in advance so she can efficiently reallocate the meeting time. Your physical and mental health are important. If you need to cancel a meeting for health or personal reasons, email Dr. Rose. As much notice as is possible is helpful, but it is always better to cancel a meeting short notice than to attend when you are sick!\nIf there are repeated meeting cancellations, we should discuss the underlying reasons.\nPlease also see Section 2.3 for details on recurring meeting agendas.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>General Policies</span>"
    ]
  },
  {
    "objectID": "chapters/02-policies.html#sec-meeting-agendas",
    "href": "chapters/02-policies.html#sec-meeting-agendas",
    "title": "2  General Policies",
    "section": "2.3 Meeting Agendas",
    "text": "2.3 Meeting Agendas\nTrainees must prepare an agenda prior to each recurring meeting with Dr. Rose. Create a google doc (invite Dr. Rose as editor) that you’ll add to in reverse chronological order for each meeting with the information below included. Update the google doc by 11AM one business day before our meeting. Repeatedly not creating agendas will result in cancelled meetings.\n[Meeting Date]\n\nWhat has been completed since previous meeting:\nTopics to discuss at the meeting:\nWhat will be completed by the next meeting:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>General Policies</span>"
    ]
  },
  {
    "objectID": "chapters/02-policies.html#individual-development-plans",
    "href": "chapters/02-policies.html#individual-development-plans",
    "title": "2  General Policies",
    "section": "2.4 Individual Development Plans",
    "text": "2.4 Individual Development Plans\nIf Dr. Rose is your primary advisor, students and postdoctoral scholars should complete the Stanford Individual Development Plan (IDP) when joining the Lab and then annually thereafter (student forms, initial form for postdocs, annual form for postdocs). This applies regardless of home department. Trainees should plan to check in on progress made toward IDP goals once a quarter. Dr. Rose expects that trainees will be responsible for scheduling the annual IDP meetings and adding the IDP check-ins once a quarter to the agenda for an existing recurring meeting.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>General Policies</span>"
    ]
  },
  {
    "objectID": "chapters/02-policies.html#academic-progress-in-graduate-degree-programs",
    "href": "chapters/02-policies.html#academic-progress-in-graduate-degree-programs",
    "title": "2  General Policies",
    "section": "2.5 Academic Progress in Graduate Degree Programs",
    "text": "2.5 Academic Progress in Graduate Degree Programs\nIf you are a graduate student and Dr. Rose is your primary advisor, please create and regularly update a shared document that includes major degree requirements (e.g., coursework, teaching, qualifying exams, etc) and completion status (e.g., completed, planned completion date). Include links at the top to the graduate degree handbook from your home department as well as key contacts in your home department who should be kept apprised of your academic progress. This document will be discussed quarterly along with the IDP check-ins, and students should add it to the agenda for an existing recurring meeting.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>General Policies</span>"
    ]
  },
  {
    "objectID": "chapters/02-policies.html#registering-for-units",
    "href": "chapters/02-policies.html#registering-for-units",
    "title": "2  General Policies",
    "section": "2.6 Registering for Units",
    "text": "2.6 Registering for Units\nGraduate students should discuss their plans to register for research units with Dr. Rose each term (often BIOMEDIN 299 or HRP 399). Units should be taken credit/no credit and not for a letter grade. Permission codes are currently required to register for research units.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>General Policies</span>"
    ]
  },
  {
    "objectID": "chapters/02-policies.html#deadlines",
    "href": "chapters/02-policies.html#deadlines",
    "title": "2  General Policies",
    "section": "2.7 Deadlines",
    "text": "2.7 Deadlines\nWe aim to set ambitious yet feasible target deadlines for work product in a collaborative process. It is often the case that research takes longer than we expect, and an internal agreed-upon deadline is no longer possible. If you anticipate missing a deadline, contact Dr. Rose. It is an expectation in the Lab that all members are proactive about discussing revised deadlines rather than waiting until after the deadline has passed. If a trainee is repeatedly missing deadlines, we should discuss the underlying reasons.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>General Policies</span>"
    ]
  },
  {
    "objectID": "chapters/02-policies.html#lab-meetings-events",
    "href": "chapters/02-policies.html#lab-meetings-events",
    "title": "2  General Policies",
    "section": "2.8 Lab Meetings & Events",
    "text": "2.8 Lab Meetings & Events\nThe Lab holds Lab Meetings and various types of events throughout the year, including lunches, data jamborees, coffee chats, and journal clubs. If you have ideas for events, suggestions are always welcome.\nFood at Lab events is funded by the Lab and free to Lab attendees. We expect that trainees who RSVP and submit food orders will show up to the event, barring illness or personal situation. If you need to change your RSVP, please contact Dr. Rose to help us avoid food waste.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>General Policies</span>"
    ]
  },
  {
    "objectID": "chapters/02-policies.html#communication",
    "href": "chapters/02-policies.html#communication",
    "title": "2  General Policies",
    "section": "2.9 Communication",
    "text": "2.9 Communication\nWe have a Lab slack. Lab members can search for “HPDS Lab” in the Workspaces at Stanford and request to join.\nPlease keep in mind our Lab philosophy on working hours in Section 1.3. Do not assume that because you have sent a slack message or email that you should get an instant reply.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>General Policies</span>"
    ]
  },
  {
    "objectID": "chapters/03-funding.html#for-graduate-students",
    "href": "chapters/03-funding.html#for-graduate-students",
    "title": "3  Funding",
    "section": "3.1 For Graduate Students",
    "text": "3.1 For Graduate Students",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Funding</span>"
    ]
  },
  {
    "objectID": "chapters/03-funding.html#for-postdoctoral-scholars",
    "href": "chapters/03-funding.html#for-postdoctoral-scholars",
    "title": "3  Funding",
    "section": "3.2 For Postdoctoral Scholars",
    "text": "3.2 For Postdoctoral Scholars",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Funding</span>"
    ]
  },
  {
    "objectID": "chapters/03-funding.html#active-lab-funding",
    "href": "chapters/03-funding.html#active-lab-funding",
    "title": "3  Funding",
    "section": "3.3 Active Lab Funding",
    "text": "3.3 Active Lab Funding\nThe Health Policy Data Science Lab at Stanford currently has three active grants where Dr. Rose is the Principal Investigator:\n\nNIH Director’s Pioneer Award\nNLM R01 Grant\nLaura and John Arnold Foundation Grant\n\nDr. Rose is also Co-Principal Investigator on the following two grants:\n\nStanford Impact Labs Grant\nStanford HAI Hoffman-Yee Grant\n\n\n3.3.1 Trainee Responsibilities on Funded Grants\n\n\n3.3.2 Reporting Requirements\n\nHourly Work\n\n\nParticipating in Interim and Annual Reports\n\n\nConflict of Interest Reporting\n\n\nFellowship & Resources Reporting\n\nFor Other Support pages",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Funding</span>"
    ]
  },
  {
    "objectID": "chapters/04-data.html#irbs",
    "href": "chapters/04-data.html#irbs",
    "title": "4  Data",
    "section": "4.1 IRBs",
    "text": "4.1 IRBs",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "chapters/04-data.html#data-at-stanford",
    "href": "chapters/04-data.html#data-at-stanford",
    "title": "4  Data",
    "section": "4.2 Data at Stanford",
    "text": "4.2 Data at Stanford\n\n4.2.1 STARR Data\nLab experts on the STARR data include Marika Cusick.\n\n\n4.2.2 Center for Population Health Sciences\nThe Center for Population Health Sciences (PHS)…\n\nMedicare Data\nLab experts on Medicare data include Marissa Reitsma.\n\n\nAmerican Family Cohort Registry\nThe American Family Cohort (AFC) Registry was created and is updated by the American Board of Family Medicine (ABFM).\nLab experts on the ABFM AFC Cohort Registry data include Agata Foryciarz, Gabriela Basel, and Marika Cusick.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "chapters/04-data.html#bringing-data-to-stanford",
    "href": "chapters/04-data.html#bringing-data-to-stanford",
    "title": "4  Data",
    "section": "4.3 Bringing Data to Stanford",
    "text": "4.3 Bringing Data to Stanford\nThe key steps in bringing a new data set to Stanford include completing submitting an IRB and a data risk assessment review.\n\n4.3.1 Data Risk Assessment\nThe data risk assessment (DRA) review process at Stanford must be followed to bring external data to Stanford. A summary of this process is included below. However, the DRA review process is subject to change and should be confirmed and followed as described on the DRA website.\n\nReview the Stanford Risk Classifications to determine the level of risk of your requested data.\nIf the requested data are high risk, then you will need to submit a DRA. If you are not sure if the data are high risk, there is also a pre-screening form that helps assess whether a DRA form is necessary.\nIn the DRA form, you will need the following information:\n\nProject information\n\nProject leader contact information\nIRB information (if applicable)\nFunding source\nAny other relevant parties involved in the project (e.g., Stanford Health Care)\nAny other individuals who will be involved with the data\n\nWho are you getting the data from? (third party)\n\nContact information (e.g., name and email address)\nData flow diagram\nAre the data going in or out of the U.S.?\n\nBrief description of the project and reason for needing this data source\nBrief description of the data source\n\nElements (e.g., lab results, diagnoses or procedures)\nNumber of records\nData dictionary (if available)\nData source (e.g., institutions and individuals involved in producing the data)\nWhether the data are identified or de-identified and how are the data de-identified? (e.g., Safe Harbor method)\n\n\nAwait the DRA review. You may get follow-up questions from the University Privacy Office, such as:\n\nHow do you plan to store the data?\nWill Stanford data be used or shared?\nWill data be shared back with the third party?\n\n\nLab experts on the DRA process include Marika Cusick.\n\n\n4.3.2 Datasets\nWe are in the process of bringing the Chronic Renal Insufficiency Cohort Study (CRIC) from NIDDK to Stanford.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "chapters/04-data.html#omop",
    "href": "chapters/04-data.html#omop",
    "title": "4  Data",
    "section": "4.4 OMOP",
    "text": "4.4 OMOP",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "chapters/04-data.html#sec-data",
    "href": "chapters/04-data.html#sec-data",
    "title": "4  Data",
    "section": "4.5 Data Sharing",
    "text": "4.5 Data Sharing\nMany of our studies involve secondary analyses of existing health databases. It is typically not permitted for us to share such data due to privacy considerations. Thus, we often created simulated data that has some similar properties to the health databases to share along with our code and published results.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "chapters/04-data.html#simulated-data",
    "href": "chapters/04-data.html#simulated-data",
    "title": "4  Data",
    "section": "4.6 Simulated Data",
    "text": "4.6 Simulated Data\nMany of our projects involve simulating data to test our methodology under situations where we know the underlying truth and because we cannot share certain health data due to privacy considerations. Simulating data is an important skill to learn.\nExamples of detailed simulation studies designed by Lab alums include work from Irina Degtiar and Anna Zink.\nNote: Creating simulated data is different than designing a microsimulation study. It can be confusing!",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "chapters/05-computing.html#nero-gcp",
    "href": "chapters/05-computing.html#nero-gcp",
    "title": "5  Computing Resources",
    "section": "5.1 Nero GCP",
    "text": "5.1 Nero GCP",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Computing Resources</span>"
    ]
  },
  {
    "objectID": "chapters/05-computing.html#sherlock",
    "href": "chapters/05-computing.html#sherlock",
    "title": "5  Computing Resources",
    "section": "5.2 Sherlock",
    "text": "5.2 Sherlock",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Computing Resources</span>"
    ]
  },
  {
    "objectID": "chapters/05-computing.html#software",
    "href": "chapters/05-computing.html#software",
    "title": "5  Computing Resources",
    "section": "5.3 Software",
    "text": "5.3 Software\nMuch of the software we use in the Lab is available open source for free. Please let Dr. Rose know if there is non-free software that would be helpful for your research and we can likely purchase this with research funds.\n\nStatistical Computing\n\nR: Download Free\nRStudio: Download Free\nPython: Download Free\n\n\n\nIllustration\n\nOmniGraffle: Purchase Subscription or One-Time Download\nAdobe Illustrator: Free via Stanford Branner Earth Science Library or Purchase Adobe Creative Cloud License",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Computing Resources</span>"
    ]
  },
  {
    "objectID": "chapters/05-computing.html#github",
    "href": "chapters/05-computing.html#github",
    "title": "5  Computing Resources",
    "section": "5.4 Github",
    "text": "5.4 Github",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Computing Resources</span>"
    ]
  },
  {
    "objectID": "chapters/06-conferences.html#conferences-by-field",
    "href": "chapters/06-conferences.html#conferences-by-field",
    "title": "6  Conferences",
    "section": "6.1 Conferences by Field",
    "text": "6.1 Conferences by Field\nWe include below a noncomprehensive list of conferences that may be of interest to Lab members.\n\nAlgorithmic Bias & Fairness\n\nACM FAccT\nAAI/ACM AI, Ethics, & Society\nACM EAAMO\nIEEE SaTML\n\n\n\nMachine Learning for Health\n\nMachine Learning for Health Care\nCHIL\nMachine Learning for Health\n\n\n\nStatistics\n\nInternational Conference on Health Policy Statistics\nENAR\nJoint Statistical Meetings\n\n\n\nHealth Economics\n\nASHEcon\niHEA\nEconomics of AI\n\n\n\nHealth Policy\n\nAcademyHealth\nISPOR\n\n\n\nDecision Science\n\nSMDM",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conferences</span>"
    ]
  },
  {
    "objectID": "chapters/06-conferences.html#stanford-travel-policies",
    "href": "chapters/06-conferences.html#stanford-travel-policies",
    "title": "6  Conferences",
    "section": "6.2 Stanford Travel Policies",
    "text": "6.2 Stanford Travel Policies\nFlights MUST be purchased through Stanford Travel. They are not reimbursable if they are purchased any other way.\nHealth Policy and Biomedical Data Science Students: If you are presenting at a conference, submit for up to $1,000 of those expenses to be reimbursed through the Biosciences Travel Grant Program. You are eligible for one conference per year and these funds should be used first before research grant resources.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conferences</span>"
    ]
  },
  {
    "objectID": "chapters/07-publications.html#authorship",
    "href": "chapters/07-publications.html#authorship",
    "title": "7  Publications",
    "section": "7.1 Authorship",
    "text": "7.1 Authorship\nWe aim to discuss authorship early in the research process and have continuing conversations regarding team member roles. Plans can change and contributions may evolve over time. If you have authorship questions during the process of working on a project, we want you to feel empowered to ask these questions! It is an expectation in the Lab that no new authors are invited to join an existing Lab project (i.e., where Dr. Rose is the lead PI) without the prior agreement of, at a minimum, Dr. Rose and the first author(s). The Lab follows the ICMJE recommendations regarding who is included as an author.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Publications</span>"
    ]
  },
  {
    "objectID": "chapters/07-publications.html#preprints",
    "href": "chapters/07-publications.html#preprints",
    "title": "7  Publications",
    "section": "7.2 Preprints",
    "text": "7.2 Preprints",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Publications</span>"
    ]
  },
  {
    "objectID": "chapters/07-publications.html#on-least-publishable-units",
    "href": "chapters/07-publications.html#on-least-publishable-units",
    "title": "7  Publications",
    "section": "7.3 On Least Publishable Units",
    "text": "7.3 On Least Publishable Units",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Publications</span>"
    ]
  },
  {
    "objectID": "chapters/07-publications.html#types-of-papers",
    "href": "chapters/07-publications.html#types-of-papers",
    "title": "7  Publications",
    "section": "7.4 Types of Papers",
    "text": "7.4 Types of Papers\nThe structure and content of a manuscript varies by discipline and audience.\nExample Lab publications by journal type: statistics, medical, health policy, health services research, health economics, computer science conference paper.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Publications</span>"
    ]
  },
  {
    "objectID": "chapters/07-publications.html#journals",
    "href": "chapters/07-publications.html#journals",
    "title": "7  Publications",
    "section": "7.5 Journals",
    "text": "7.5 Journals\nThe journal lists below are not exhaustive and largely focus on outlets where Lab members have previously published their work. Decisions about where to submit manuscripts for publication are made collaboratively to balance the needs and priorities of the team with as much deference as possible to what is best for the trainee author(s).\n\nHealth Economics & Policy\nJournal of Health Economics, American Journal of Health Economics, Health Affairs, Health Services Research, Medical Care, Medical Decision Making, JAMA Health Forum\n\n\nEpidemiology & Public Health\nAmerican Journal of Epidemiology, Epidemiology, International Journal of Epidemiology, American Journal of Public Health\n\n\nStatistics\nJournal of the American Statistical Association, Biometrics, Biostatistics (COI: Sherri is Co-Editor-in-Chief), Statistics in Medicine, Statistical Methods in Medical Research\n\n\nClinical\nNEJM, JAMA, JAMA Internal Medicine, JAMA Psychiatry\n\n\nHealth Informatics & Digital Health\nJAMIA, BMJ Health & Care Informatics, Lancet Digital Health",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Publications</span>"
    ]
  },
  {
    "objectID": "chapters/09-code-workflow-agreements.html#team-agreements",
    "href": "chapters/09-code-workflow-agreements.html#team-agreements",
    "title": "8  Code Workflow Team Agreements",
    "section": "8.1 Team Agreements",
    "text": "8.1 Team Agreements\nThis chapter documents the code workflow team agreements for our lab. By team agreements, we mean a set of coding principles and workflows we have all agreed to adhere to. This is a living document: we can update as the team and coding ecosystem change over time. If you have concerns or suggestions about our workflows, feel free to propose alternatives for the team to consider collectively.\nWe focus on workflows that allow individual members freedom to code how they prefer while maintaining reproducibility and ease of collaboration. Thus, we don’t tell you which language to use or, for the most part, which tools to use within a given language (unless there is a key tool we use to maintain the agreements).\nCurrently, most of our team uses R, Python, or both. Thus, we offer language-specific guidance for those two languages. We’ll add relevant recommendations if other languages become more prominent in the team.\nThroughout this document, we’ll organize language-specific guidance in tab sets like this:\n\nRPython\n\n\nThis is how we do it in R.\n\n\nThis is how we do it in Python.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nContact Malcolm for support if you want help setting up or using any guidelines in this document.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Code Workflow Team Agreements</span>"
    ]
  },
  {
    "objectID": "chapters/10-pre-flight-checklist.html#crosscheck",
    "href": "chapters/10-pre-flight-checklist.html#crosscheck",
    "title": "9  Pre-Flight Checklist for Publications",
    "section": "9.1 Crosscheck",
    "text": "9.1 Crosscheck\nAs discussed in ?sec-code-review and Chapter 8, your analysis should be regularly checked for correctness and adherence to lab agreements, not just at the end of the project. However, it’s useful to have a final check (by you and at least one other person) before submitting for publication. Regular code review will make this final check quicker and easier, so please do both.\nNote: for pre-prints, run through this checklist for both uploading to the pre-print server as well as for when you formally submit the project to a journal.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pre-Flight Checklist for Publications</span>"
    ]
  },
  {
    "objectID": "chapters/10-pre-flight-checklist.html#pre-flight-checklist",
    "href": "chapters/10-pre-flight-checklist.html#pre-flight-checklist",
    "title": "9  Pre-Flight Checklist for Publications",
    "section": "9.2 Pre-Flight Checklist",
    "text": "9.2 Pre-Flight Checklist\n\n9.2.1 Repository and files\n\nNo sensitive data is included in the repository. If such data is identified, remove from repo and git history. Check files, Jupyter caches, etc.\nThere is a README file (any of: README.md, README.Rmd, README.qmd)\nREADME contains clear instructions on how to run the code. See Section 8.7.2 for details.\nIf repo is private, make it public\n\n\n\n9.2.2 Code and reproducibility\n\nThe code follows the team style guide. See Section 8.2 for details.\nQuery code from user interfaces, e.g., Redivis or BigQuery, are up to date in version control\nThe code uses a package environment to lock packages. See Section 8.9 for details.\nManuscript is generatable via Quarto. See See Section 8.5 for details.\nRun the code one last time in a fresh environment, preferably on a different computer. See Section 8.8 for details.\n\n\n\n9.2.3 Submission\n\nCheck any Data Use Agreements for relevant datasets that require review from a third party\nCheck if journal has specific code and reproducibility guidelines\nCheck figures and tables for correctness\nCheck https://www.zotero.org/styles for a citation style file for the journal of interest, and include the file in your Quarto metadata and in the repository\nFor sensitive data, no small cells (&lt;11) are included in tables or figures (future: run x tool on output to make sure)\nShare with co-authors for comments\nUse a GitHub release for the submission version. See Section 8.6.1 for details.\nSubmit to archive service like OSF\nIf there are any research outputs other than a journal article, such as a dataset, register them for a DOI at a service like OSF or Zenodo\n\n\n\n9.2.4 Acceptance\n\nIf the project exists as a pre-print, update the pre-print page to include information about the peer-reviewed publication.\n\n\n\n9.2.5 Opt-in Workflows (Section 8.10)\n\nOpt-in: if code contains tests, tests pass. See Section 8.10.2 for details.\nOpt-in: Pipeline code is documented and with clear instructions for running the pipeline. See ?sec-pipeline for details.\nOpt-in: Dockerfile is included in repository with clear instructions for running the image. See Section 8.10.3 for details.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pre-Flight Checklist for Publications</span>"
    ]
  },
  {
    "objectID": "chapters/09-code-workflow-agreements.html#todo",
    "href": "chapters/09-code-workflow-agreements.html#todo",
    "title": "8  Code Workflow Team Agreements",
    "section": "8.12 TODO",
    "text": "8.12 TODO",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Code Workflow Team Agreements</span>"
    ]
  },
  {
    "objectID": "chapters/09-code-workflow-agreements.html#code-style",
    "href": "chapters/09-code-workflow-agreements.html#code-style",
    "title": "8  Code Workflow Team Agreements",
    "section": "8.2 Code style",
    "text": "8.2 Code style\nConsistency of code style is essential for collaboration. It speeds up the reading of code and reduces debates on what code should look like. We prefer automated styling tools such that you can write however you like and quickly follow the team style guide by running the tool.\n\nRPython\n\n\nR code should follow the Tidyverse style guide, automatically styled by the styler package. Despite the name, this guide also applies to non-Tidyverse code, including base R and data.table.\n# style all R-related files in the current directory\nstyler::style_dir()\nNote that you should run styler interactively in the console, not in one of your R scripts.\nStyler also has a helpful add-in for RStudio to let you style the active file, a code selection, etc.\n\n\nFor Python, we use TODO.\nTODO: Decide on a code style Option 1: ruff\nRuff uses the Black style guide is more performant and extensible.\nRuff is installable through pip:\npip install ruff\nRun this command in the terminal to format the Python code in your directory:\nruff format\nOption 2: black\nBlack uses the Black style guide.\nBlack is installable through pip:\npip install black\nRun this command in the terminal to format the Python code in your directory:\nblack .\nOption 3: rye\nRye is a global Python manager. It uses the Ruff to format Python code using the Black style guide.\nRye is not installable via pip; follow the instructions on the website to install it.\nRun this command in the terminal to format the Python code in your directory:\nrye fmt\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nWe do not currently require a linter, but they can be handy to analyze your code for areas of improvement.\n\nRPython\n\n\nIn R, use lintr. Linting works particularly well in RStudio, which will tag lines of code with specific suggestions.\n\nlintr::lint_dir()\n\n\n\nIn Python, use TODO.\nNote: black does not have a linter, but Ruff and Rye do. For black, Flake8 might be the complementary linter\nNote: Quarto files are not widely supported yet. See this issue for ruff: https://github.com/astral-sh/ruff/issues/6140",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Code Workflow Team Agreements</span>"
    ]
  },
  {
    "objectID": "chapters/09-code-workflow-agreements.html#python-1",
    "href": "chapters/09-code-workflow-agreements.html#python-1",
    "title": "8  Code Workflow Team Agreements",
    "section": "8.3 Python",
    "text": "8.3 Python\nFor Python, we use TODO.\n\n\nRuff uses the Black style guide is more performant and extensible.\nRuff is installable through pip:\npip install ruff\nRun this command in the terminal to format the Python code in your directory:\nruff format\n\nBlack uses the Black style guide.\nBlack is installable through pip:\npip install black\nRun this command in the terminal to format the Python code in your directory:\nblack .\n\nRye is a global Python manager. It uses the Ruff to format Python code using the Black style guide.\nRye is not installable via pip; follow the instructions on the website to install it.\nRun this command in the terminal to format the Python code in your directory:\nrye fmt\n\n\n\n\n\n\nTip\n\n\n\n\nRPython\n\n\nIn R, use lintr. This works particularly well in RStudio, which will tag lines of code with specific suggestions.\n\nlintr::lint_dir()\n\n\n\nIn Python, use TODO.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Code Workflow Team Agreements</span>"
    ]
  },
  {
    "objectID": "chapters/09-code-workflow-agreements.html#naming-things",
    "href": "chapters/09-code-workflow-agreements.html#naming-things",
    "title": "8  Code Workflow Team Agreements",
    "section": "8.3 Naming things",
    "text": "8.3 Naming things\nNaming things is an aspect of code style, but it merits a little extra attention because it is important to readability. In general, strive to make your code self-documenting, e.g., someone else should be able to read your code and understand what it’s doing without talking to you about it. Self-documenting is easier said than done, so code clearness is an essential type of feedback in code review.\nUse descriptive names for objects in code, e.g., model_results instead of out or kangaroo_data instead of k.\n\n\n\n\n\n\nTip\n\n\n\nIt’s OK to use terse names where the meaning is generally understood, like n for counts or i and j for loop counters.\n\n\nSimilarly, for functions, describe what the function is doing, preferably in verb format, e.g., simulate_data() is better than f() or data_simulator()\nFor both R and Python, prefer snake_case over camelCase and other naming style conventions unless otherwise appropriate, e.g., the name of a class for object-oriented programming in Python.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Code Workflow Team Agreements</span>"
    ]
  },
  {
    "objectID": "chapters/09-code-workflow-agreements.html#project-organization",
    "href": "chapters/09-code-workflow-agreements.html#project-organization",
    "title": "8  Code Workflow Team Agreements",
    "section": "8.4 Project organization",
    "text": "8.4 Project organization\nWe try to be flexible about project organization, as being too prescriptive often backfires. The rule of thumb is to try to make it obvious where everything is by using descriptive folder and file names, e.g., R/ or scripts/ to organize source code and output or reports to organize research outputs. You should also include guidance on the organization of your project in a README (see Section 8.7.2).\nFor instance, an R project might look like this:\nR/\nfigures/\nreports/\nmy_project.Rproj\nor like\nsql/\nfunctions/\nrun.R\nmy_project.Rproj\nBoth setups are understandable and reasonable; the vital part is that users know where to find important files and how to use them.\nThere are a few tools that will help you set up a project.\n\nRPython\n\n\nRStudio supports the idea of RStudio Projects. These are handy setups because they set your working directory wherever your project is on your computer. See See Project-Oriented Workflows for more.\nUse the RStudio interface to create a new project or create one in the console with usethis::create_project(\"/path/to/your/new/project\").\n\n\nif we use Rye\nFor Python users, running rye init project_name will set up a directory called project_name with several files pre-established as a git repository.\n\n\n\nWe also have a couple of essential guidelines for what is in a project.\n\n8.4.1 Don’t include sensitive information on Git and GitHub\n.gitignore any sensitive data. For instance, your .gitignore file should contain lines for data/ and data-raw/ if those two folders contain sensitive data. Another common source of information leaks is cached data, such as Jupyter checkpoints or a knitr cache.\n\n\n\n\n\n\nTip\n\n\n\nFor R users, consider running usethis::git_vaccinate() in the console. Running this command will add standard R-related files that shouldn’t be in version control to your global gitignore. It won’t protect you from including sensitive data, but it serves as a backup configuration for files that usually don’t need to be included.\nusethis also has a function called use_git_ignore() for adding files and folders to .gitignore, which might feel more natural to the R workflow.\n\n\nA project that has sensitive data and uses Jupyter might have a .gitignore file in the root directory that looks like this:\ndata/\n.ipynb_checkpoints\n*/__pycache__\nHere, data/ is ignored because it contains sensitive data, .ipynb_checkpoints is ignored because it might accidentally have such data, and __pycache__ is ignored not because it is a data cache (despite its name) but that it’s a commonly ignored development output in Python projects.\n\n\n\n\n\n\nTip\n\n\n\nSee GitHub’s collection of commonly gitignored files and folders organized by programming language for more suggestions on files you might want to exclude from your repository. Not all these are related to sensitive information; some are output objects considered unnecessary or cluttering.\n\n\n\n\n8.4.2 Don’t include absolute directories that are not accessible to others\nA common mistake in code is to hardcode a path that only exists on your computer, e.g.\ndf = pd.read_csv(\"/users/malcolmbarrett/Downloads/data.csv\")\nPrefer file paths that are relative to the root directory of your project. data.csv should be in my project directory, which I can access with relative paths:\ndf = pd.read_csv(\"data/data.csv\")\n\n\n\n\n\n\nTip\n\n\n\nFor R users, the here package can let you refer to files and folders from the root directory of your project no matter where the code exists. here can be helpful when, for instance, you have a report in a reports/ folder but want to refer to a data file in the data/ folder. Instead of backtracking ../data/data.csv, you can write here(\"data\", \"data.csv\")",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Code Workflow Team Agreements</span>"
    ]
  },
  {
    "objectID": "chapters/09-code-workflow-agreements.html#documentation",
    "href": "chapters/09-code-workflow-agreements.html#documentation",
    "title": "8  Code Workflow Team Agreements",
    "section": "8.7 Documentation",
    "text": "8.7 Documentation\nThe first step in documenting your code is writing clear, readable code. In other words, someone else should be able to read your code and understand what it’s doing. The best way to test this out is a code review: can somebody else understand your code? Code that is itself readable is sometimes called self-documenting code. It’s not always possible and shouldn’t be the only type of documentation, but it’s an excellent goal to strive towards.\n\n8.7.1 A note about comments\nComments exist in virtually every programming language because programming languages are for humans, not computers. Adding commentary is essential to making it understandable to a person.\nThat said, many comments are of two less helpful varieties: what comments and deodorant comments. “What” comments explain what the code is doing, usually redundantly. This type of comment is unnecessary because it’s clear from the code what is happening:\n# add 1 and 2 together\n1 + 2\nDeodorant comments are added because the code is unclear. This idea comes from what Martin Fowler calls “code smells”, a particular odor in code that suggests a more profound problem or lack of clarity.\n\n…comments aren’t a bad smell; indeed they are a sweet smell. The reason we mention comments here is that comments often are used as a deodorant.\n\nSometimes, blocks of comments explain code that could be refactored to be more straightforward:\n\nWhen you feel the need to write a comment, first try to refactor the code so that any comment becomes superfluous\n\nAgain, code comments are not bad. They are helpful and sometimes downright necessary. Some code is unavoidably complex, so context as to why and what the code is doing makes it more understandable.\nWhen you get feedback in a code review that something is hard to understand, try to clarify the code, then add comments as necessary.\n\n\n8.7.2 README\nA README file is commonly included in a project to explain how to use it or other relevant information. README.md files have special properties on GitHub. These are text files that use markdown syntax. When you visit a repository on GitHub, the README is rendered and serves as a front page for your project. You can manually include a README.md file or render one with a README.Rmd or README.qmd file.\n\n\n\n\n\n\nTip\n\n\n\nFor R users, running usethis::use_readme_md() and usethis::use_readme_rmd() will create README.md and README.Rmd, respectively. You only need to pick one of these.\n\nFor Python users, rye init will automatically create a README.md file.\n\n\nFor our purposes, a README should include at least:\n\nA description of the project, such as an abstract\nA brief explanation of the file structure of the repository\nDetails on how to run the code (Section 8.8) in the project, such as installing dependencies, versions of R or Python for the project, etc.\nAny other necessary information to understand or use the project",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Code Workflow Team Agreements</span>"
    ]
  },
  {
    "objectID": "chapters/09-code-workflow-agreements.html#running-code",
    "href": "chapters/09-code-workflow-agreements.html#running-code",
    "title": "8  Code Workflow Team Agreements",
    "section": "8.6 Running code",
    "text": "8.6 Running code",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Code Workflow Team Agreements</span>"
    ]
  },
  {
    "objectID": "chapters/09-code-workflow-agreements.html#opt-in-workflows",
    "href": "chapters/09-code-workflow-agreements.html#opt-in-workflows",
    "title": "8  Code Workflow Team Agreements",
    "section": "8.10 Opt-in Workflows",
    "text": "8.10 Opt-in Workflows\nOpt-in workflows are things we do not require for a project but for which we offer guidance. Such workflows also allow the team to experiment with new things and see what works for projects and when.\n\n8.10.1 Release on GitHub\nGitHub has a mechanism for making formal releases of repositories. This takes a snapshot of the repository at the time of release and attaches a name.\nMaking a “release”, of course, has its origins in software versions. However, it’s also helpful in tracking significant milestones in a project. For instance, make a release upon submission to a journal and another upon publication. That allows you to easily view the state of the repository at those two time points. GitHub also makes downloading the repository in releases easy, making it an excellent point to direct people not using Git.\n\n\n8.10.2 Pipelines\nPipeline tools are software that manage the execution of code. What’s practical about this for research projects is that pipeline tools track the relationship between components in your project (meaning it knows which order to run things in automatically) and will only run those components when they are out of date (meaning you don’t necessarily need to rerun your entire project because you updated one part of the code).\nPipeline tools are helpful for projects of any size, but they are particularly suited to complex or computationally intense projects.\n\nRPython\n\n\nThe best pipeline tool in R is the targets package. targets is a native R tool, making it easy to work with R objects. It works particularly well with Quarto and R Markdown, allowing you to reduce the amount of code in a report while managing it reproducibly.\ntargets has excellent documentation and tutorials, so we point you there for guidance.\nIt’s also possible to use tools like Make and Snakemake, among others (see the Python tab), with R, although we recommend targets for projects that are mostly R.\n\n\nTODO: decide on which to use\nPython has several pipeline tools that are used in data engineering. For these larger data projects, these tools are sometimes called orchestration tools. That said, many of them are much more complex than is needed for a single research project.\nHere are the tools we should explore:\n\nMake: Make is one of the oldest and most popular pipeline tools, over 40 years old. It shows its age in some ways, but it’s also battle-tested. See this tutorial for an example of running an analysis with Make.\nSnakemake: a Python tool influenced by Make, it’s very similar in spirit but more modern. It’s easier to read and customize, and you can write Python code within the Snakefile. It also works nicely with Python and R scripts. One handy thing is that you can access Snakemake inputs and outputs through magic objects for both Python and R. That makes it useful for, e.g., dynamic rules and rules where you want to use inputs for reports. Snakemake has good support for Conda environments in particular.\nDagster. Dagster is a different approach that uses decorators to tag Python functions as “assets,” the apparent equivalent of targets in other tools. It has a nice UI tool for visualizing the nodes and relationships of the project, as well as “materializing” (running) them. Dagster is a company, but the tool has an open-source version.\nPrefect Prefect is an increasingly popular tool for orchestration. Like Dagster, it is a company-based open-source tool that uses decorators to tag Python functions. It also has a UI.\n\n\n\n\n\n\n8.10.3 Testing\nIn scientific work, two types of code tests are useful: code expectations and data expectations. Code should behave the way you expect, and data should exist the way you expect. If that is not the case, you either have identified a problem with your code and data or a problem with your expectations.\nAutomating such tests in code expectations is helpful because you can run them whenever you have code or data changes. Moreover, you’re probably already probing these expectations informally in some form or another.\n\nRPython\n\n\nYou can write code tests using simple tools in base R like stop() and stopifnot(), but the most robust suite for testing code is the testthat package. While testthat is designed for R packages, it’s also useful for testing functions in your analysis code. In addition to the testthat documentation, see the testing chapter of R Packages for more.\nThere are several tools for testing data. Again, you can use simple logical statements with stop() and friends, but the most comprehensive tool in R for data quality checks is pointblank.\nIn RStudio, you can automate tests even when you’re not in a package by activating “package mode”. All this means is adding a DESCRIPTION file. To do this, run usethis::use_description(check_name = FALSE) and restart RStudio. Then, you can run any tests in the test/ folder via the Build pane.\n\n\nYou can write code tests using simple tools in Python like assert, but there are also many libraries for formal testing. The most popular is unittest.\nThere are several tools for testing data. Again, you can use simple logical statements with assert and friends, but the most comprehensive tool in Python for data quality checks is Great Expectations.\n\n\n\n\n\n8.10.4 Docker\nDocker is a tool for reproducing not just the software and packages used in an analysis but the entire computational environment. As it’s got more of a learning curve, we do not currently require it for projects. However, consider it for projects where reproducibility is crucial or where you want to feel more confident that the code will be runable for many years.\nDocker is a general tool that works with R, Python, and just about anything else you like to use.\nHere’s a Docker tutorial for data analysis: https://github.com/RamiKrispin/sdsu-docker-workshop.\nIf interest in Docker grows on the team, we’ll also explore creating support for Docker workflows, such as prebuilt images and Dockerfiles the team can lean on.\n\nRPython\n\n\nDocker doesn’t require a different approach for R, but many existing images save time. Here is an overview of running R code in Docker: https://raps-with-r.dev/repro_cont.html.\n\n\nDocker doesn’t require a different approach for Python, but some Python-specific tools will save time. Here’s a tutorial on setting up and using Docker with Python in VS Code: https://github.com/RamiKrispin/vscode-python",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Code Workflow Team Agreements</span>"
    ]
  },
  {
    "objectID": "chapters/09-code-workflow-agreements.html#generate-reproducible-documents-with-quarto",
    "href": "chapters/09-code-workflow-agreements.html#generate-reproducible-documents-with-quarto",
    "title": "8  Code Workflow Team Agreements",
    "section": "8.5 Generate reproducible documents with Quarto",
    "text": "8.5 Generate reproducible documents with Quarto\nPrefer using Quarto for documents, particularly those that generate a research product like a journal article. Quarto is a scientific publishing framework that weaves Markdown-based text with computational results from R, Python, Julia, etc. You can also mix languages in a single document.\nYou can also use Quarto interactively in RStudio and VS Code much as you can with R Markdown or Jupyter notebooks.\nThe documentation on the Quarto website is excellent, so check that for guidance on the latest features. A handy collection of pages for research is the Scholarly Writing section of the Authoring guide.\n\nRPython\n\n\nRStudio comes with an installation of Quarto, so you likely don’t need to install it. However, if you install a newer version of Quarto, RStudio will use that automatically, making it reasonably seamless to upgrade.\nIf you prefer, you can also use R and Quarto in VS Code.\nPrefer Quarto over R Markdown; Quarto supersedes R Markdown and all significant improvements and developments will be there instead of R Markdown.\n\n\nPrefer Quarto .qmd files over Jupyter files; Quarto can run interactively like a notebook but has better reproducibility and version control properties. That said, you can use both using Quarto to render Jupyter files. Quarto also has tooling for switching back and forth between formats.\nThe best way to use Quarto for Python projects is VS Code using the Quarto extension. This extension allows you to render files easily while also running code interactively. RStudio also supports Python projects, so it’s another good option if you also use R.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Code Workflow Team Agreements</span>"
    ]
  },
  {
    "objectID": "chapters/09-code-workflow-agreements.html#lock-your-package-versions",
    "href": "chapters/09-code-workflow-agreements.html#lock-your-package-versions",
    "title": "8  Code Workflow Team Agreements",
    "section": "8.9 Lock your package versions",
    "text": "8.9 Lock your package versions\nInstalling project dependencies is a part of running code, but its peculiarities for reproducibility merit some attention of its own.\nBoth packages within a language and languages themselves frequently change, making running code over time (as new versions are released) and space (the versions on your computer vs. someone else’s computer) difficult.\nA vital check of this problem is code review. The reviewer serves as a proxy for being able to run your code somewhere else. If it doesn’t work for your reviewer, discuss and document the process to make it so.\nThere are also tools for installing versions of packages local to the project such that a project will always use identical package versions.\n\n\n\n\n\n\nNote\n\n\n\nWe leave it up to the project’s author when they activate a package environment manager. Sometimes, waiting while you iterate through a project, adding and removing dependencies as you go, is helpful. Sometimes, it’s easier to start in a controlled environment.\nAt the very least, your project should end in such a state. The last check for this is pre-submission (Chapter 9).\n\n\nHere are the tools we use for managing software versions.\n\nRPython\n\n\nIn R, use the renv package to manage R package versions. renv is an interactive tool, so you should use it primarily in the console.\nTo initiate a project:\nrenv::init()\nAmong other things, this will create renv.lock, which needs to be included in your git repository.\nCheck a project’s dependency status with\nrenv::status()\nAnd update the packages in your lock file with\nrenv::snapshot()\nWhen you use renv, your project README should explain how to use it, e.g.\n# install.packages(\"renv\")\n# install the dependencies for the project\nrenv::restore()\nOne common problem in renv is that it keeps track of but does not manage the R version. If you need to switch between R versions, consider using rig. Rig is not an R package but a separate software that lets you install and switch between R versions. On servers, RStudio Workbench will let you change versions, as well, provided that they are installed.\n\n\nNote: The Python ecosystem for managing environments is vast. See https://alpopkes.com/posts/python/packaging_tools/ for an overview.\nWe need to decide which approach to use.\nManaging Python packages\nOption 1: venv + pip\n# create a new virtual environment called projectenv\npython3 -m venv projectenv\n\n# activate the environment projectenv\nsource projectenv/bin/activate\n\n# add a package to your environment\npip install polars\nOption 2: conda\n# create a new virtual environment called projectenv\nconda create --name projectenv\n\n# activate the environment projectenv\nconda activate projectenv\n\n# add a package to your environment\nconda install polars\nOption 3: rye\n# after `rye init project_name` and `rye pin python_version`, create the virtual environment:\nrye sync\n\n# activate the environment \n. .venv/bin/activate\n\n# add a package to your environment\nrye add polars\nManaging Python versions\nOption 1: pyenv\n# install python 3.12.1\npyenv install 3.12.1\n\n# use python 3.12.1 for the local project\npyenv local 3.12.1\nOption 2: conda\nConda treats Python like other packages, so managing it is similar. One helpful thing you can do is specify a Python version while creating an environment.\n# create a new virtual environment called projectenv\nconda create --name projectenv python=3.12.1\n\n# activate the environment projectenv\nconda activate projectenv\nSee the Conda documentation for other ways of interacting with the Python version.\nOption 3: rye\n# use python 3.12.1 for the local project\nrye pin 3.12.1\n\n# install the pinned version, python 3.12.1\nrye fetch",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Code Workflow Team Agreements</span>"
    ]
  },
  {
    "objectID": "chapters/09-code-workflow-agreements.html#sec-running-code",
    "href": "chapters/09-code-workflow-agreements.html#sec-running-code",
    "title": "8  Code Workflow Team Agreements",
    "section": "8.8 Running code",
    "text": "8.8 Running code\n\n8.8.1 Use a blank slate\nYou should regularly run your code in a blank slate—running everything from scratch.\n\nRPython\n\n\nBy default, R stores and loads the interactive environment you use between R sessions. This is a bad default for reproducibility. Teach R not to do this by running this command once in your terminal:\nusethis::use_blank_slate()\nRelatedly, your script should not contain rm(list = ls()). Using a blank slate and restarting your R session is the better approach because it really starts from scratch, whereas rm(list = ls()) only clears objects in the global environment. See Project-Oriented Workflows for a discussion on this.\n\n\nIn Python, the primary way that people end up with environments that are out of sync with their code is by not regularly restarting their Jupyter kernel. Instead, regularly restart the kernel and run all cells to make sure your code still works (and works as you expect).\nNote that this applies only to Jupyter Notebooks. While Quarto uses the Jupyter kernel for running Python code, it always starts a new session when rendering.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nRendering a Quarto document always runs code from scratch by default.\n\n\n\n\n8.8.2 Provide guidance on how to run your code\nYour README should include guidance on how to run your code. For instance, if there is a command to run the entire project, include information about that process (this is usually related to pipeline-managed code as discussed in the optional Section 8.10.1). If you intend the user to run scripts in a particular order, describe how.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Code Workflow Team Agreements</span>"
    ]
  },
  {
    "objectID": "chapters/09-code-workflow-agreements.html#dont-include-sensitive-information-on-git-and-github",
    "href": "chapters/09-code-workflow-agreements.html#dont-include-sensitive-information-on-git-and-github",
    "title": "8  Code Workflow Team Agreements",
    "section": "8.5 Don’t include sensitive information on git and GitHub",
    "text": "8.5 Don’t include sensitive information on git and GitHub\n.gitignore any sensitive data. For instance, your .gitignore file should contain lines for data/ and data-raw/ if those two folders contain sensitive data. Another common source of information leak is cached data, such as Jupyter checkpoints or a knitr cache.\n\n\n\n\n\n\nTip\n\n\n\nFor R users, consider running usethis::git_vaccinate() in the console. This will add common R-related files that shouldn’t be in version control to your global gitignore. It won’t protect you from including sensitive data, but it serves as a backup configuration for files that usually don’t need to be included.\nusethis also has a function called use_git_ignore() for adding files and folders to .gitignore which might feel more natural to the R workflow.\n\n\nA project that has sensitive data and uses Jupyter might have a .gitignore file in the root directory that looks like this:\ndata/\n.ipynb_checkpoints\n*/__pycache__\nHere, data/ is ignored because it contains sensitive data, .ipynb_checkpoints is ignored because it might accidentally contain such data and __pycache__ is ignored not because it is a data cache (despite its name) but that it’s a commonly ignored development output in Python projects.\n\n\n\n\n\n\nTip\n\n\n\nSee GitHub’s collection of commonly gitignored files and folders organized by programming language for more suggestions on files you might want to exclude from your repository. Not all of these are related to sensitive information; some are output objects that are considered unnecessary or cluttering.\n\n\n\n8.5.1 Don’t include absolute directories that are not accessible to others\nA common mistake in code is to hardcode a path that only exists on your computer, e.g.\ndf = pd.read_csv(\"/users/malcolmbarrett/Downloads/data.csv\")\nPrefer file paths that are relative to the root directory of your project. data.csv should be in my project directory, which I can access with relative paths:\ndf = pd.read_csv(\"data/data.csv\")\n\n\n\n\n\n\nTip\n\n\n\nFor R users, the here package can let you refer to files and folders from the root directory of your project no matter where the code exists. This can be helpful when, for instance, you have a report in a reports/ folder but you want to refer to a data file in the data/ folder. Instead of backtracking ../data/data.csv, you can write here(\"data\", \"data.csv\")",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Code Workflow Team Agreements</span>"
    ]
  },
  {
    "objectID": "chapters/09-code-workflow-agreements.html#python-3",
    "href": "chapters/09-code-workflow-agreements.html#python-3",
    "title": "8  Code Workflow Team Agreements",
    "section": "8.5 Python",
    "text": "8.5 Python\nif we use rye\nFor Python users, running rye init project_name will set up a directory called project_name with several files and pre-established as a git repository. :::\n\n8.5.1 Don’t include sensitive information on git and GitHub\n.gitignore any sensitive data. For instance, your .gitignore file should contain lines for data/ and data-raw/ if those two folders contain sensitive data. Another common source of information leak is cached data, such as Jupyter checkpoints or a knitr cache.\n\n\n\n\n\n\nTip\n\n\n\nFor R users, consider running usethis::git_vaccinate() in the console. This will add common R-related files that shouldn’t be in version control to your global gitignore. It won’t protect you from including sensitive data, but it serves as a backup configuration for files that usually don’t need to be included.\nusethis also has a function called use_git_ignore() for adding files and folders to .gitignore which might feel more natural to the R workflow.\n\n\nA project that has sensitive data and uses Jupyter might have a .gitignore file in the root directory that looks like this:\ndata/\n.ipynb_checkpoints\n*/__pycache__\nHere, data/ is ignored because it contains sensitive data, .ipynb_checkpoints is ignored because it might accidentally contain such data and __pycache__ is ignored not because it is a data cache (despite its name) but that it’s a commonly ignored development output in Python projects.\n\n\n\n\n\n\nTip\n\n\n\nSee GitHub’s collection of commonly gitignored files and folders organized by programming language for more suggestions on files you might want to exclude from your repository. Not all of these are related to sensitive information; some are output objects that are considered unnecessary or cluttering.\n\n\n\n\n8.5.2 Don’t include absolute directories that are not accessible to others\nA common mistake in code is to hardcode a path that only exists on your computer, e.g.\ndf = pd.read_csv(\"/users/malcolmbarrett/Downloads/data.csv\")\nPrefer file paths that are relative to the root directory of your project. data.csv should be in my project directory, which I can access with relative paths:\ndf = pd.read_csv(\"data/data.csv\")\n\n\n\n\n\n\nTip\n\n\n\nFor R users, the here package can let you refer to files and folders from the root directory of your project no matter where the code exists. This can be helpful when, for instance, you have a report in a reports/ folder but you want to refer to a data file in the data/ folder. Instead of backtracking ../data/data.csv, you can write here(\"data\", \"data.csv\")",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Code Workflow Team Agreements</span>"
    ]
  },
  {
    "objectID": "chapters/09-code-workflow-agreements.html#use-git-and-github",
    "href": "chapters/09-code-workflow-agreements.html#use-git-and-github",
    "title": "8  Code Workflow Team Agreements",
    "section": "8.6 Use Git and GitHub",
    "text": "8.6 Use Git and GitHub\nYou should manage your project with version control and hosted for collaborators to access. We use Git and GitHub for managing and hosting version-controlled repositories, respectfully. We also have a GitHub organization where we keep team projects.\nSee ?sec-code-review for how to manage code changes to your repository.\n\n\n\n\n\n\nTip\n\n\n\nFor R users, there are two helpful functions in usethis to manage your git setup for a project: usethis::use_git() will initialize a git repository and activate the git UI in RStudio; usethis::use_github() will create and link a GitHub repository, as well as make your first push. Note that use_github() has an organisation argument where you can specify a GitHub organization to create the repository under, such as use_github(organisation = \"StanfordHPDS\").\nSee also the PR workflow vignette for making and managing pull requests in R. You might also find Happy Git and GitHub for the useR a helpful perspective.\n\n\n\n8.6.1 Release on GitHub\nGitHub has a mechanism for making formal releases of repositories. This takes a snapshot of the repository at the time of release and attaches a name.\nMaking a “release”, of course, has its origins in software versions. However, it’s also helpful in tracking significant milestones in a project. For instance, make a release upon submission to a journal and another upon publication. That allows you to easily revisit the state of the repository at those two time points. GitHub also makes downloading the repository in releases easy, making it an excellent point to direct people not using Git.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Code Workflow Team Agreements</span>"
    ]
  },
  {
    "objectID": "chapters/09-code-workflow-agreements.html#finishing-projects",
    "href": "chapters/09-code-workflow-agreements.html#finishing-projects",
    "title": "8  Code Workflow Team Agreements",
    "section": "8.13 Finishing projects",
    "text": "8.13 Finishing projects",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Code Workflow Team Agreements</span>"
    ]
  },
  {
    "objectID": "chapters/09-code-workflow-agreements.html#code-style-sec-code-style",
    "href": "chapters/09-code-workflow-agreements.html#code-style-sec-code-style",
    "title": "8  Code Workflow Team Agreements",
    "section": "8.2 Code style {sec-code-style}",
    "text": "8.2 Code style {sec-code-style}\nConsistency of code style is essential for collaboration. It speeds up the reading of code and reduces debates on what code should look like. We prefer automated styling tools such that you can write however you like and quickly follow the team style guide by running the tool.\n\nRPython\n\n\nR code should follow the Tidyverse style guide, automatically styled by the styler package. Despite the name, this guide also applies to non-Tidyverse code, including base R and data.table.\n# style all R-related files in the current directory\nstyler::style_dir()\nNote that you should run styler interactively in the console, not in one of your R scripts.\nStyler also has a helpful add-in for RStudio to let you style the active file, a code selection, etc.\n\n\nFor Python, we use TODO.\nTODO: Decide on a code style Option 1: ruff\nRuff uses the Black style guide is more performant and extensible.\nRuff is installable through pip:\npip install ruff\nRun this command in the terminal to format the Python code in your directory:\nruff format\nOption 2: black\nBlack uses the Black style guide.\nBlack is installable through pip:\npip install black\nRun this command in the terminal to format the Python code in your directory:\nblack .\nOption 3: rye\nRye is a global Python manager. It uses the Ruff to format Python code using the Black style guide.\nRye is not installable via pip; follow the instructions on the website to install it.\nRun this command in the terminal to format the Python code in your directory:\nrye fmt\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nWe do not currently require a linter, but they can be handy to analyze your code for areas of improvement.\n\nRPython\n\n\nIn R, use lintr. Linting works particularly well in RStudio, which will tag lines of code with specific suggestions.\n\nlintr::lint_dir()\n\n\n\nIn Python, use TODO.\nNote: black does not have a linter, but Ruff and Rye do. For black, Flake8 might be the complementary linter\nNote: Quarto files are not widely supported yet. See this issue for ruff: https://github.com/astral-sh/ruff/issues/6140",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Code Workflow Team Agreements</span>"
    ]
  },
  {
    "objectID": "chapters/09-code-workflow-agreements.html#sec-code-style",
    "href": "chapters/09-code-workflow-agreements.html#sec-code-style",
    "title": "8  Code Workflow Team Agreements",
    "section": "8.2 Code style",
    "text": "8.2 Code style\nConsistency of code style is essential for collaboration. It speeds up the reading of code and reduces debates on what code should look like. We prefer automated styling tools such that you can write however you like and quickly follow the team style guide by running the tool.\n\nRPython\n\n\nR code should follow the Tidyverse style guide, automatically styled by the styler package. Despite the name, this guide also applies to non-Tidyverse code, including base R and data.table.\n# style all R-related files in the current directory\nstyler::style_dir()\nNote that you should run styler interactively in the console, not in one of your R scripts.\nStyler also has a helpful add-in for RStudio to let you style the active file, a code selection, etc.\n\n\nFor Python, we use TODO.\nTODO: Decide on a code style Option 1: ruff\nRuff uses the Black style guide is more performant and extensible.\nRuff is installable through pip:\npip install ruff\nRun this command in the terminal to format the Python code in your directory:\nruff format\nOption 2: black\nBlack uses the Black style guide.\nBlack is installable through pip:\npip install black\nRun this command in the terminal to format the Python code in your directory:\nblack .\nOption 3: rye\nRye is a global Python manager. It uses the Ruff to format Python code using the Black style guide.\nRye is not installable via pip; follow the instructions on the website to install it.\nRun this command in the terminal to format the Python code in your directory:\nrye fmt\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nWe do not currently require a linter, but they can be handy to analyze your code for areas of improvement.\n\nRPython\n\n\nIn R, use lintr. Linting works particularly well in RStudio, which will tag lines of code with specific suggestions.\n\nlintr::lint_dir()\n\n\n\nIn Python, use TODO.\nNote: black does not have a linter, but Ruff and Rye do. For black, Flake8 might be the complementary linter\nNote: Quarto files are not widely supported yet. See this issue for ruff: https://github.com/astral-sh/ruff/issues/6140",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Code Workflow Team Agreements</span>"
    ]
  },
  {
    "objectID": "chapters/09-code-workflow-agreements.html#sec-quarto",
    "href": "chapters/09-code-workflow-agreements.html#sec-quarto",
    "title": "8  Code Workflow Team Agreements",
    "section": "8.5 Generate reproducible documents with Quarto",
    "text": "8.5 Generate reproducible documents with Quarto\nPrefer using Quarto for documents, particularly those that generate a research product like a journal article. Quarto is a scientific publishing framework that weaves Markdown-based text with computational results from R, Python, Julia, etc. You can also mix languages in a single document.\nYou can also use Quarto interactively in RStudio and VS Code much as you can with R Markdown or Jupyter notebooks.\nThe documentation on the Quarto website is excellent, so check that for guidance on the latest features. A handy collection of pages for research is the Scholarly Writing section of the Authoring guide.\n\nRPython\n\n\nRStudio comes with an installation of Quarto, so you likely don’t need to install it. However, if you install a newer version of Quarto, RStudio will use that automatically, making it reasonably seamless to upgrade.\nIf you prefer, you can also use R and Quarto in VS Code.\nPrefer Quarto over R Markdown; Quarto supersedes R Markdown and all significant improvements and developments will be there instead of R Markdown.\n\n\nPrefer Quarto .qmd files over Jupyter files; Quarto can run interactively like a notebook but has better reproducibility and version control properties. That said, you can use both using Quarto to render Jupyter files. Quarto also has tooling for switching back and forth between formats.\nThe best way to use Quarto for Python projects is VS Code using the Quarto extension. This extension allows you to render files easily while also running code interactively. RStudio also supports Python projects, so it’s another good option if you also use R.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Code Workflow Team Agreements</span>"
    ]
  },
  {
    "objectID": "chapters/09-code-workflow-agreements.html#sec-pkg-env",
    "href": "chapters/09-code-workflow-agreements.html#sec-pkg-env",
    "title": "8  Code Workflow Team Agreements",
    "section": "8.9 Lock your package versions",
    "text": "8.9 Lock your package versions\nInstalling project dependencies is a part of running code, but its peculiarities for reproducibility merit some attention of its own.\nBoth packages within a language and languages themselves frequently change, making running code over time (as new versions are released) and space (the versions on your computer vs. someone else’s computer) difficult.\nA vital check of this problem is code review. The reviewer serves as a proxy for being able to run your code somewhere else. If it doesn’t work for your reviewer, discuss and document the process to make it so.\nThere are also tools for installing versions of packages local to the project such that a project will always use identical package versions.\n\n\n\n\n\n\nNote\n\n\n\nWe leave it up to the project’s author when they activate a package environment manager. Sometimes, waiting while you iterate through a project, adding and removing dependencies as you go, is helpful. Sometimes, it’s easier to start in a controlled environment.\nAt the very least, your project should end in such a state. The last check for this is pre-submission (Chapter 9).\n\n\nHere are the tools we use for managing software versions.\n\nRPython\n\n\nIn R, use the renv package to manage R package versions. renv is an interactive tool, so you should use it primarily in the console.\nTo initiate a project:\nrenv::init()\nAmong other things, this will create renv.lock, which needs to be included in your git repository.\nCheck a project’s dependency status with\nrenv::status()\nAnd update the packages in your lock file with\nrenv::snapshot()\nWhen you use renv, your project README should explain how to use it, e.g.\n# install.packages(\"renv\")\n# install the dependencies for the project\nrenv::restore()\nOne common problem in renv is that it keeps track of but does not manage the R version. If you need to switch between R versions, consider using rig. Rig is not an R package but a separate software that lets you install and switch between R versions. On servers, RStudio Workbench will let you change versions, as well, provided that they are installed.\n\n\nNote: The Python ecosystem for managing environments is vast. See https://alpopkes.com/posts/python/packaging_tools/ for an overview.\nWe need to decide which approach to use.\nManaging Python packages\nOption 1: venv + pip\n# create a new virtual environment called projectenv\npython3 -m venv projectenv\n\n# activate the environment projectenv\nsource projectenv/bin/activate\n\n# add a package to your environment\npip install polars\nOption 2: conda\n# create a new virtual environment called projectenv\nconda create --name projectenv\n\n# activate the environment projectenv\nconda activate projectenv\n\n# add a package to your environment\nconda install polars\nOption 3: rye\n# after `rye init project_name` and `rye pin python_version`, create the virtual environment:\nrye sync\n\n# activate the environment \n. .venv/bin/activate\n\n# add a package to your environment\nrye add polars\nManaging Python versions\nOption 1: pyenv\n# install python 3.12.1\npyenv install 3.12.1\n\n# use python 3.12.1 for the local project\npyenv local 3.12.1\nOption 2: conda\nConda treats Python like other packages, so managing it is similar. One helpful thing you can do is specify a Python version while creating an environment.\n# create a new virtual environment called projectenv\nconda create --name projectenv python=3.12.1\n\n# activate the environment projectenv\nconda activate projectenv\nSee the Conda documentation for other ways of interacting with the Python version.\nOption 3: rye\n# use python 3.12.1 for the local project\nrye pin 3.12.1\n\n# install the pinned version, python 3.12.1\nrye fetch",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Code Workflow Team Agreements</span>"
    ]
  },
  {
    "objectID": "chapters/09-code-workflow-agreements.html#sec-opt-in",
    "href": "chapters/09-code-workflow-agreements.html#sec-opt-in",
    "title": "8  Code Workflow Team Agreements",
    "section": "8.10 Opt-in Workflows",
    "text": "8.10 Opt-in Workflows\nOpt-in workflows are things we do not require for a project but for which we offer guidance. Such workflows also allow the team to experiment with new things and see what works for projects and when.\n\n8.10.1 Pipelines\nPipeline tools are software that manage the execution of code. What’s practical about this for research projects is that pipeline tools track the relationship between components in your project (meaning it knows which order to run things in automatically) and will only run those components when they are out of date (meaning you don’t necessarily need to rerun your entire project because you updated one part of the code).\nPipeline tools are helpful for projects of any size, but they are particularly suited to complex or computationally intense projects.\n\nRPython\n\n\nThe best pipeline tool in R is the targets package. targets is a native R tool, making it easy to work with R objects. It works particularly well with Quarto and R Markdown, allowing you to reduce the amount of code in a report while managing it reproducibly.\ntargets has excellent documentation and tutorials, so we point you there for guidance.\nIt’s also possible to use tools like Make and Snakemake, among others (see the Python tab), with R, although we recommend targets for projects that are mostly R.\n\n\nTODO: decide on which to use\nPython has several pipeline tools that are used in data engineering. For these larger data projects, these tools are sometimes called orchestration tools. That said, many of them are much more complex than is needed for a single research project.\nHere are the tools we should explore:\n\nMake: Make is one of the oldest and most popular pipeline tools, over 40 years old. It shows its age in some ways, but it’s also battle-tested. See this tutorial for an example of running an analysis with Make.\nSnakemake: a Python tool influenced by Make, it’s very similar in spirit but more modern. It’s easier to read and customize, and you can write Python code within the Snakefile. It also works nicely with Python and R scripts. One handy thing is that you can access Snakemake inputs and outputs through magic objects for both Python and R. That makes it useful for, e.g., dynamic rules and rules where you want to use inputs for reports. Snakemake has good support for Conda environments in particular.\nDagster. Dagster is a different approach that uses decorators to tag Python functions as “assets,” the apparent equivalent of targets in other tools. It has a nice UI tool for visualizing the nodes and relationships of the project, as well as “materializing” (running) them. Dagster is a company, but the tool has an open-source version.\nPrefect Prefect is an increasingly popular tool for orchestration. Like Dagster, it is a company-based open-source tool that uses decorators to tag Python functions. It also has a UI.\n\n\n\n\n\n\n8.10.2 Testing\nIn scientific work, two types of code tests are useful: code expectations and data expectations. Code should behave the way you expect, and data should exist the way you expect. If that is not the case, you either have identified a problem with your code and data or a problem with your expectations.\nAutomating such tests in code expectations is helpful because you can run them whenever you have code or data changes. Moreover, you’re probably already probing these expectations informally in some form or another.\n\nRPython\n\n\nYou can write code tests using simple tools in base R like stop() and stopifnot(), but the most robust suite for testing code is the testthat package. While testthat is designed for R packages, it’s also useful for testing functions in your analysis code. In addition to the testthat documentation, see the testing chapter of R Packages for more.\nThere are several tools for testing data. Again, you can use simple logical statements with stop() and friends, but the most comprehensive tool in R for data quality checks is pointblank.\nIn RStudio, you can automate tests even when you’re not in a package by activating “package mode”. All this means is adding a DESCRIPTION file. To do this, run usethis::use_description(check_name = FALSE) and restart RStudio. Then, you can run any tests in the test/ folder via the Build pane.\n\n\nYou can write code tests using simple tools in Python like assert, but there are also many libraries for formal testing. The most popular is unittest.\nThere are several tools for testing data. Again, you can use simple logical statements with assert and friends, but the most comprehensive tool in Python for data quality checks is Great Expectations.\n\n\n\n\n\n8.10.3 Docker\nDocker is a tool for reproducing not just the software and packages used in an analysis but the entire computational environment. As it’s got more of a learning curve, we do not currently require it for projects. However, consider it for projects where reproducibility is crucial or where you want to feel more confident that the code will be runable for many years.\nDocker is a general tool that works with R, Python, and just about anything else you like to use.\nHere’s a Docker tutorial for data analysis: https://github.com/RamiKrispin/sdsu-docker-workshop.\nIf interest in Docker grows on the team, we’ll also explore creating support for Docker workflows, such as prebuilt images and Dockerfiles the team can lean on.\n\nRPython\n\n\nDocker doesn’t require a different approach for R, but many existing images save time. Here is an overview of running R code in Docker: https://raps-with-r.dev/repro_cont.html.\n\n\nDocker doesn’t require a different approach for Python, but some Python-specific tools will save time. Here’s a tutorial on setting up and using Docker with Python in VS Code: https://github.com/RamiKrispin/vscode-python",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Code Workflow Team Agreements</span>"
    ]
  }
]